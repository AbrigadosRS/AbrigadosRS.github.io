const { GoogleAuth } = require('google-auth-library');
const { v1 } = require('@google-cloud/aiplatform');
const axios = require('axios');

// Substitua pela sua API Key
require('dotenv').config();
const API_KEY = process.env.API_KEY;

// Crie a instÃ¢ncia do Google Auth
const auth = new GoogleAuth({
  scopes: ['https://www.googleapis.com/auth/cloud-platform'],
});

// Crie o cliente para o Google Generative AI
const client = new v1.PredictionServiceClient({
  apiEndpoint: 'us-central1-aiplatform.googleapis.com', 
  credentials: auth.getApplicationDefault(), 
});

// FunÃ§Ã£o para extrair dados do script PHP
async function extractDataFromPHP() {
  try {
    const response = await axios.get('buscardbchat.php');
    const data = response.data;
    return data;
  } catch (error) {
    console.error('Erro ao consultar o script PHP:', error);
    throw error; 
  }
}

// ConfiguraÃ§Ãµes do modelo Gemini
const generationConfig = {
  temperature: 1,
  topP: 0.95,
  topK: 0,
  maxOutputTokens: 8192,
};

const safetySettings = [
  { category: 'HARM_CATEGORY_HARASSMENT', threshold: 'BLOCK_MEDIUM_AND_ABOVE' },
  { category: 'HARM_CATEGORY_HATE_SPEECH', threshold: 'BLOCK_MEDIUM_AND_ABOVE' },
  { category: 'HARM_CATEGORY_SEXUALLY_EXPLICIT', threshold: 'BLOCK_MEDIUM_AND_ABOVE' },
  { category: 'HARM_CATEGORY_DANGEROUS_CONTENT', threshold: 'BLOCK_MEDIUM_AND_ABOVE' },
];

// FunÃ§Ã£o para enviar uma mensagem ao Gemini e obter a resposta
async function sendMessage(messages) {
  const request = {
    endpoint: `projects/${process.env.GOOGLE_CLOUD_PROJECT}/locations/us-central1/publishers/google/models/gemini-1.5-pro-latest`,
    parameters: {
      temperature: generationConfig.temperature,
      topP: generationConfig.topP,
      topK: generationConfig.topK,
      maxOutputTokens: generationConfig.maxOutputTokens,
    },
    instance: {
      context: {
        messages: messages.map(msg => ({
          author: msg.role,
          content: msg.parts.join('\n'),
        })),
      },
    },
  };

  const [response] = await client.predict(request);
  const message = response.predictions[0].text;
  return message;
}

// FunÃ§Ã£o principal
async function main() {
  try {
    let conversationHistory = [
      {
        role: 'user',
        parts: await extractDataFromPHP(), 
      },
      {
        role: 'user',
        parts: ["VocÃª Ã© um gestor de uma plataforma de abrigos de animais da enchente de 2024 no rio grande do sul. O seu Trabalho Ã© ajudar as pessoas que acessarem o site a definir qual abrigo elas devem fornecer a sua ajuda, com base na cidade em que elas moram, na disponibilidade de recurso que elas tem e nos abrigos que apresentam maior necessidade. \nA tabela enviada contÃ©m os dados dos abrigos registrados na plataforma. Comece a conversa Perguntando o nome a cidade de quem estÃ¡ entrando no chat. Pergunte o que a pessoa estÃ¡ disposta a oferecer e com base na resposta dela, analise a tabela para definir qual abrigo ela deve ajudar primeiro.\nFaÃ§a uma pergunta de cada vez.\nVocÃª tambÃ©m pode se sentir livre para usar emojis que representem a causa animal (cÃ£es, gatos, etc)"]
      },
      {
        role: 'model',
        parts: ["OlÃ¡! ğŸ‘‹ Sou um guia para te ajudar a encontrar o abrigo ideal para vocÃª oferecer sua ajuda ğŸ™. Para comeÃ§armos, me diga: qual o seu nome e a cidade onde vocÃª mora? ğŸ¶ğŸ±"]
      },
    ];

    console.log(await sendMessage(conversationHistory));

    // Loop para continuar a conversa
    while (true) {
      const userInput = prompt("YOUR_USER_INPUT: ");
      conversationHistory.push({ role: 'user', parts: [userInput] });

      const response = await sendMessage(conversationHistory);
      console.log(response);
    }

  } catch (error) {
    console.error('Ocorreu um erro:', error);
  }
}

main();